# ğŸ•µï¸â€â™‚ï¸ Self-Supervised Image Tampering Detection using Forensic Cues

## ğŸ“Œ Project Overview

With the widespread use of image editing tools and social media platforms, digital images are often manipulated through operations such as **splicing, copyâ€“move forgery, and retouching**. These manipulations can be subtle and visually indistinguishable to the human eye, making manual verification unreliable.

This project presents a **self-supervised image tampering detection system** that identifies manipulated images **without using labeled tampering data during training**. Instead of relying on deep learning classifiers, the system leverages **classical image forensics cues** and **unsupervised anomaly detection** to determine whether an image deviates from the statistical characteristics of authentic images.

---

## ğŸ¯ Key Objectives

* Detect whether an image is **authentic (clean)** or **manipulated**
* Avoid the need for labeled tampering data during training
* Provide **explainable forensic evidence**, not just a binary decision
* Use lightweight, interpretable image processing techniques

---

## ğŸ§  Core Idea

> **Authentic images follow consistent statistical patterns.
> Manipulated images disrupt these patterns.**

The system is trained only on **authentic images** to learn what "normal" image statistics look like. During testing, any image that significantly deviates from this learned distribution is flagged as **tampered**.

This makes the approach:

* **Self-supervised**
* **Dataset-agnostic**
* **Robust to unseen manipulation types**

---

## ğŸ” Forensic Features Used

The system extracts multiple forensic cues from each image:

### ğŸ¨ Color Statistics

* Mean, standard deviation, and skewness of RGB channels
* Manipulations often introduce unnatural color distributions

### âœ‚ï¸ Edge Artifacts

* Edge density and sharpness using gradient analysis
* Splicing and copyâ€“paste operations break natural edge continuity

### ğŸŒ«ï¸ Noise Patterns

* Sensor noise residuals
* Edited regions often have inconsistent noise characteristics

---

## ğŸ¤– Anomaly Detection Model

* **Isolation Forest** (unsupervised)
* Trained only on authentic images
* Produces:

  * **Binary decision**: Clean / Manipulated
  * **Anomaly confidence score** (degree of suspicion)

---

## ğŸ“Š Output and Explainability

For each test image, the system reports:

* **Tampering decision** (Clean / Manipulated)
* **Anomaly confidence score**
* **Color statistics deviation**
* **Edge inconsistency strength**
* **Noise pattern abnormality**

### Example Output

```
âš ï¸ Manipulated | score=-0.3271 | color_dev=18.42 | edge_inconsistency=0.0813 | noise_abnormality=12.47 | Tp_034.jpg
```

This ensures the system is **interpretable**, not a black box.

---

## ğŸ“ Project Structure

```
CV/
â”œâ”€â”€ train.py                  # Self-supervised training script
â”œâ”€â”€ detect.py                 # Inference with explainable output
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ train/            # Authentic images only
â”‚   â”‚   â””â”€â”€ test/             # Test images (clean + tampered)
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ color_stats.py
â”‚   â”œâ”€â”€ edge_artifacts.py
â”‚   â””â”€â”€ noise_patterns.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ anomaly_model.py
â””â”€â”€ utils/
    â””â”€â”€ preprocessing.py
```

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Train the Model (Self-Supervised)

```bash
python train.py
```

* Uses only images from `data/raw/train`
* Saves trained model to `models/model.pkl`

### 3ï¸âƒ£ Detect Image Tampering

```bash
python detect.py
```

* Tests the first 25 images by default
* Prints detailed forensic evidence per image

---

## ğŸ“š Dataset Usage

* **Authentic images** are used for training
* **Tampered images** are used only for evaluation
* Ground-truth masks (if available) are **never used during training**

This preserves the integrity of the self-supervised setup.

---

## ğŸ§ª Applications

* Digital image forensics
* Social media misinformation detection
* Journalism and media verification
* Law enforcement and cybercrime analysis
* Academic research in explainable computer vision

---

## ğŸ§  Key Takeaway

> This project demonstrates that **effective image manipulation detection does not require deep learning or labeled datasets**, and that classical image processing combined with anomaly detection can produce **robust, explainable forensic systems**.

---

## ğŸš€ Future Enhancements

* Patch-wise tampering localization (heatmaps)
* Ground-truth-based quantitative evaluation
* Automatic forensic report generation
* Comparison with deep learning baselines

---

## ğŸ“„ License

This project is open-source and available for academic and research purposes.

---

## ğŸ‘¨â€ğŸ’» Author

Sudarshan K Naik

**Repository:** https://github.com/SudarshanKNaik/CV-Tampered-Image-Detection-
